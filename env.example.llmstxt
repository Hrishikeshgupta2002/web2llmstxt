# LLMs.txt Generator Configuration
# Copy values and update as needed

# =============================================================================
# AI MODEL CONFIGURATION
# =============================================================================
# Gemini API Configuration
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# Ollama Configuration (for local models)
# Default: http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# PROCESSING CONFIGURATION
# =============================================================================
# Output directory for generated files
# Default: ./output
OUTPUT_DIR=./output

# Maximum tokens for AI generation
# Default: 1024
MAX_GEN_OUTPUT_TOKENS=1024

# Enable/disable description caching
# Default: true
CACHE_DESCRIPTIONS=true

# Default number of parallel workers for processing
# Default: 3 (reduced automatically for local models)
DEFAULT_PARALLEL_WORKERS=3
# =============================================================================
# SECURITY NOTES
# =============================================================================
# - Never commit your .env file with real API keys to version control
# - Add .env to your .gitignore file
